{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "End-To-End Training",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lukassanting/Idiom-Translation/blob/main/End_To_End_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training T5 - Prefix+Idiom\n",
        "\n"
      ],
      "metadata": {
        "id": "rEADq27OKFe6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#0. Installs, Imports, Setup\n"
      ],
      "metadata": {
        "id": "v9dFeYBSZJJb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##0.1 Import Libraries & Packages"
      ],
      "metadata": {
        "id": "I8njKcE7c2F4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece -q\n",
        "!pip install transformers -q\n",
        "!pip install torch -q\n",
        "!pip install rich[jupyter] -q"
      ],
      "metadata": {
        "id": "dEFESOlJb8yT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drive\n",
        "from google.colab import drive\n",
        "\n",
        "# Plots\n",
        "import IPython\n",
        "import IPython.display\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Util\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "# ML\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Importing the T5 modules from huggingface/transformers\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# rich: for a better display on terminal\n",
        "from rich.table import Column, Table\n",
        "from rich.text import Text\n",
        "from rich import box\n",
        "from rich.console import Console\n",
        "\n",
        "# define a rich console logger\n",
        "console = Console(record=True)\n",
        "\n",
        "# Setting up the device for GPU usage\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "4mcA2ya5ZNCM",
        "outputId": "a388a940-720b-4248-f67b-cad855e4963f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##0.2. Import Data"
      ],
      "metadata": {
        "id": "s3arh9WcZFww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Either upload the data to the shared Google Drive and use this to download, or upload it directly yourself (whatever is easier)"
      ],
      "metadata": {
        "id": "zK4I5s9gZqxI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoQUPYjsZDiq",
        "outputId": "73924b2a-8088-4eb2-bc5c-762e21513129"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'data' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/marziehf/IdiomTranslationDS data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##0.3 Setup functions & classes"
      ],
      "metadata": {
        "id": "xnpSL43tdGvk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###0.3.1 FUNC: display_df"
      ],
      "metadata": {
        "id": "mKt7_iGUeScN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to display dataframe in ASCII format\n",
        "def display_df(df):\n",
        "    \"\"\"display dataframe in ASCII format\"\"\"\n",
        "\n",
        "    console = Console()\n",
        "    table = Table(\n",
        "        Column(\"source_text\", justify=\"center\"),\n",
        "        Column(\"target_text\", justify=\"center\"),\n",
        "        title=\"Sample Data\",\n",
        "        pad_edge=False,\n",
        "        box=box.ASCII,\n",
        "    )\n",
        "\n",
        "    for i, row in enumerate(df.values.tolist()):\n",
        "        table.add_row(row[0], row[1])\n",
        "\n",
        "    console.print(table)"
      ],
      "metadata": {
        "id": "QjO6nIJGchxq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###0.3.2 CLASS: DataSet"
      ],
      "metadata": {
        "id": "5v2GZNnvea0H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Dataset class for reading and loading the dataset into the dataloader, and then feed it into the neural network for fine-tuning the model."
      ],
      "metadata": {
        "id": "e1KXqhYhdX_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataSet(Dataset):\n",
        "    \"\"\"\n",
        "    Creating a dataset class for reading the dataset and\n",
        "    loading it into the dataloader, to pass it to the\n",
        "    neural network for finetuning the model\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, dataframe, tokenizer, source_len, target_len, source_text, target_text\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initializes a Dataset class\n",
        "\n",
        "        Args:\n",
        "            dataframe (pandas.DataFrame): Input dataframe\n",
        "            tokenizer (transformers.tokenizer): Transformers tokenizer\n",
        "            source_len (int): Max length of source text\n",
        "            target_len (int): Max length of target text\n",
        "            source_text (str): column name of source text\n",
        "            target_text (str): column name of target text\n",
        "        \"\"\"\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.source_len = source_len\n",
        "        self.summ_len = target_len\n",
        "        self.target_text = self.data[target_text]\n",
        "        self.source_text = self.data[source_text]\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"returns the length of dataframe\"\"\"\n",
        "\n",
        "        return len(self.target_text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"return the input ids, attention masks and target ids\"\"\"\n",
        "\n",
        "        source_text = str(self.source_text[index])\n",
        "        target_text = str(self.target_text[index])\n",
        "\n",
        "        # cleaning data so as to ensure data is in string type\n",
        "        source_text = \" \".join(source_text.split())\n",
        "        target_text = \" \".join(target_text.split())\n",
        "\n",
        "        source = self.tokenizer.batch_encode_plus(\n",
        "            [source_text],\n",
        "            max_length=self.source_len,\n",
        "            pad_to_max_length=True,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        target = self.tokenizer.batch_encode_plus(\n",
        "            [target_text],\n",
        "            max_length=self.summ_len,\n",
        "            pad_to_max_length=True,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        source_ids = source[\"input_ids\"].squeeze()\n",
        "        source_mask = source[\"attention_mask\"].squeeze()\n",
        "        target_ids = target[\"input_ids\"].squeeze()\n",
        "        target_mask = target[\"attention_mask\"].squeeze()\n",
        "\n",
        "        return {\n",
        "            \"source_ids\": source_ids.to(dtype=torch.long),\n",
        "            \"source_mask\": source_mask.to(dtype=torch.long),\n",
        "            \"target_ids\": target_ids.to(dtype=torch.long),\n",
        "            \"target_ids_y\": target_ids.to(dtype=torch.long),\n",
        "        }"
      ],
      "metadata": {
        "id": "iJmDbxNbdKlP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###0.3.3 FUNC: train"
      ],
      "metadata": {
        "id": "rcxgONn0efui"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train function, which will the put model on training mode, generate outputs and calculate loss"
      ],
      "metadata": {
        "id": "noK0ICH4eCzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch, tokenizer, model, device, loader, optimizer, train_batch_size):\n",
        "\n",
        "    \"\"\"\n",
        "    Function to be called for training with the parameters passed from main function\n",
        "\n",
        "    Takes 6 arguments as input:\n",
        "    \n",
        "        epoch: epoch\n",
        "        tokenizer: T5 tokenizer\n",
        "        model: T5 model\n",
        "        loader: Train Dataloader\n",
        "        optimizer: Optimizer\n",
        "        train_batch_size: batch size for the training data\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    train_batches = 0\n",
        "    for _, data in enumerate(loader, 0):\n",
        "        y = data[\"target_ids\"].to(device, dtype=torch.long)\n",
        "        y_ids = y[:, :-1].contiguous()\n",
        "        lm_labels = y[:, 1:].clone().detach()\n",
        "        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
        "        ids = data[\"source_ids\"].to(device, dtype=torch.long)\n",
        "        mask = data[\"source_mask\"].to(device, dtype=torch.long)\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=ids,\n",
        "            attention_mask=mask,\n",
        "            decoder_input_ids=y_ids,\n",
        "            labels=lm_labels,\n",
        "        )\n",
        "        loss = outputs[0]\n",
        "        train_loss += loss.item()\n",
        "        train_batches += 1\n",
        "\n",
        "        # Print training loss every 100 batches\n",
        "        if _ % 100 == 0:\n",
        "            #training_logger.add_row(str(epoch), str(_), str(loss.item()))\n",
        "            console.print(\"Epoch: \", str(epoch), \"Batch: \", str(_), \"Loss: \", str(loss.item()))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward() \n",
        "        optimizer.step()\n",
        "\n",
        "    # Print average training loss over the epoch\n",
        "    train_loss = train_loss/train_batches\n",
        "    training_logger.add_row(str(epoch), str(train_loss))\n"
      ],
      "metadata": {
        "id": "EG5eKLajeFKX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###0.3.4 FUNC: validate"
      ],
      "metadata": {
        "id": "K2ChKAx-em7b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validate function is same as the Train function, but for the validation data\n",
        "\n"
      ],
      "metadata": {
        "id": "o7UaCBo7eKqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(epoch, tokenizer, model, device, loader, generate_outputs=True):\n",
        "\n",
        "  \"\"\"\n",
        "  Function to evaluate model for predictions\n",
        "\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "  predictions = []\n",
        "  actuals = []\n",
        "  val_loss = 0\n",
        "  batches = 0\n",
        "  with torch.no_grad():\n",
        "      for _, data in enumerate(loader, 0):\n",
        "          y = data['target_ids'].to(device, dtype = torch.long)\n",
        "          ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "          mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "          # Find validation loss\n",
        "          y_ids = y[:, :-1].contiguous()\n",
        "          lm_labels = y[:, 1:].clone().detach()\n",
        "          lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
        "\n",
        "          outputs = model(\n",
        "              input_ids=ids,\n",
        "              attention_mask=mask,\n",
        "              decoder_input_ids=y_ids,\n",
        "              labels=lm_labels\n",
        "              )\n",
        "          loss = outputs[0]\n",
        "          val_loss += loss.item()\n",
        "          batches += 1\n",
        "\n",
        "          # Generate outputs\n",
        "          if generate_outputs:\n",
        "            generated_ids = model.generate(\n",
        "                input_ids = ids,\n",
        "                attention_mask = mask, \n",
        "                max_length=150, \n",
        "                num_beams=2,\n",
        "                repetition_penalty=2.5, \n",
        "                length_penalty=1.0, \n",
        "                early_stopping=True\n",
        "                )\n",
        "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
        "            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n",
        "\n",
        "            predictions.extend(preds)\n",
        "            actuals.extend(target)\n",
        "\n",
        "  # Save average loss over epoch\n",
        "  val_loss = val_loss/batches\n",
        "  if not generate_outputs:\n",
        "    validation_logger.add_row(str(epoch), str(val_loss))\n",
        "\n",
        "  return predictions, actuals"
      ],
      "metadata": {
        "id": "JRHNbfg1eMlx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###0.3.5 FUNC: T5Trainer"
      ],
      "metadata": {
        "id": "F19iHSPfes84"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "T5Trainer is our main function. It accepts input data, model type, model paramters to fine-tune the model. Under the hood, it utilizes, our Dataset class for data handling, train function to fine tune the model, validate to evaluate the model."
      ],
      "metadata": {
        "id": "uu9v__Wjexl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def T5Trainer(\n",
        "    train_data, val_data, source_text, target_text, model_params, output_dir=\"./outputs/\"\n",
        "):\n",
        "\n",
        "    \"\"\"\n",
        "    T5 trainer has 6 arguments:\n",
        "\n",
        "      train_data: Input dataframe of training data\n",
        "      val_data: Input dataframe of validation data\n",
        "      source_text: Column name of the input text i.e. idiomatic sentence\n",
        "      target_text: Column name of the target text i.e. literal sentence\n",
        "      model_params: T5 model parameters\n",
        "      output_dir: Output directory to save fine tuned T5 model.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Set random seeds and deterministic pytorch for reproducibility\n",
        "    torch.manual_seed(model_params[\"SEED\"])  # pytorch random seed\n",
        "    np.random.seed(model_params[\"SEED\"])  # numpy random seed\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "    # logging\n",
        "    console.log(f\"\"\"[Model]: Loading {model_params[\"MODEL\"]}...\\n\"\"\")\n",
        "\n",
        "    # tokenizer for encoding the text\n",
        "    tokenizer = T5Tokenizer.from_pretrained(model_params[\"MODEL\"])\n",
        "\n",
        "    # Defining the model. The model is then sent to device (GPU/TPU)\n",
        "    model = T5ForConditionalGeneration.from_pretrained(model_params[\"MODEL\"])\n",
        "    model = model.to(device)\n",
        "\n",
        "    # logging\n",
        "    console.log(f\"[Data]: Reading data...\\n\")\n",
        "\n",
        "    # Importing the raw dataset\n",
        "    train_data = train_data[[source_text, target_text]]\n",
        "    train_data = train_data.reset_index(drop=True)\n",
        "    val_data = val_data[[source_text, target_text]]\n",
        "    val_data = val_data.reset_index(drop=True)\n",
        "\n",
        "    display_df(train_data.head(2))\n",
        "\n",
        "    # Creation of Dataset and Dataloader\n",
        "    console.print(f\"TRAIN Dataset: {train_data.shape}\")\n",
        "    console.print(f\"VALIDATION Dataset: {val_data.shape}\\n\")\n",
        "\n",
        "    # Creating the Training and Validation dataset for further creation of Dataloader\n",
        "    training_set = DataSet(\n",
        "        train_data,\n",
        "        tokenizer,\n",
        "        model_params[\"MAX_SOURCE_TEXT_LENGTH\"],\n",
        "        model_params[\"MAX_TARGET_TEXT_LENGTH\"],\n",
        "        source_text,\n",
        "        target_text,\n",
        "    )\n",
        "    val_set = DataSet(\n",
        "        val_data,\n",
        "        tokenizer,\n",
        "        model_params[\"MAX_SOURCE_TEXT_LENGTH\"],\n",
        "        model_params[\"MAX_TARGET_TEXT_LENGTH\"],\n",
        "        source_text,\n",
        "        target_text,\n",
        "    )\n",
        "\n",
        "    # Defining the parameters for creation of dataloaders\n",
        "    train_params = {\n",
        "        \"batch_size\": model_params[\"TRAIN_BATCH_SIZE\"],\n",
        "        \"shuffle\": True,\n",
        "        \"num_workers\": 0,\n",
        "    }\n",
        "\n",
        "    val_params = {\n",
        "        \"batch_size\": model_params[\"VALID_BATCH_SIZE\"],\n",
        "        \"shuffle\": False,\n",
        "        \"num_workers\": 0,\n",
        "    }\n",
        "\n",
        "    # Creation of Dataloaders for training and validation.\n",
        "    training_loader = DataLoader(training_set, **train_params)\n",
        "    val_loader = DataLoader(val_set, **val_params)\n",
        "\n",
        "    # Defining the optimizer that will be used to tune the weights of the network in the training session.\n",
        "    optimizer = torch.optim.Adam(\n",
        "        params=model.parameters(), lr=model_params[\"LEARNING_RATE\"]\n",
        "    )\n",
        "\n",
        "    # Training loop\n",
        "    console.log(f\"[Initiating Fine Tuning]...\\n\")\n",
        "\n",
        "    train_batch_size = model_params[\"TRAIN_BATCH_SIZE\"]\n",
        "    for epoch in range(model_params[\"TRAIN_EPOCHS\"]):\n",
        "        train(epoch, tokenizer, model, device, training_loader, optimizer, train_batch_size)\n",
        "        validate(epoch, tokenizer, model, device, val_loader, generate_outputs=False)\n",
        "\n",
        "    console.print(\"\\n\")\n",
        "    console.print(training_logger)\n",
        "    console.print(\"\\n\")\n",
        "    console.print(validation_logger)\n",
        "\n",
        "    console.log(f\"[Saving Model]...\\n\")\n",
        "    # Saving the model after training\n",
        "    path = os.path.join(output_dir, \"model_files\")\n",
        "    model.save_pretrained(path)\n",
        "    tokenizer.save_pretrained(path)\n",
        "\n",
        "    # generating output for validation dataset\n",
        "    console.log(f\"[Generating Validation Outputs]...\\n\")\n",
        "    predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n",
        "    final_df = pd.DataFrame({\"Input\": val_data[source_text], \"Generated Text\": predictions, \"Actual Text\": actuals})\n",
        "    final_df.to_csv(os.path.join(output_dir, \"predictions.csv\"))\n",
        "\n",
        "    console.save_text(os.path.join(output_dir, \"logs.txt\"))\n",
        "\n",
        "    console.log(f\"[Validation Outputs Generated.]\\n\")\n",
        "    console.print(\n",
        "        f\"\"\"[Model] Model saved @ {os.path.join(output_dir, \"model_files\")}\\n\"\"\"\n",
        "    )\n",
        "    console.print(\n",
        "        f\"\"\"[Validation] Generation on Validation data saved @ {os.path.join(output_dir,'predictions.csv')}\\n\"\"\"\n",
        "    )\n",
        "    console.print(f\"\"\"[Logs] Logs saved @ {os.path.join(output_dir,'logs.txt')}\\n\"\"\")"
      ],
      "metadata": {
        "id": "cDZUWpwKev_4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Processing Data"
      ],
      "metadata": {
        "id": "FcKQWqxse_q6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_dataset(data):\n",
        "  data_clean = data.copy(deep=True)\n",
        "  for i in range(len(data_clean.columns)):\n",
        "    data_clean.iloc[:,i] = data_clean.iloc[:,i].apply(lambda x: re.sub('&apos;', '\\'', x))\n",
        "    data_clean.iloc[:,i] = data_clean.iloc[:,i].apply(lambda x: re.sub('&quot;', '\\\"', x))\n",
        "    data_clean.iloc[:,i] = data_clean.iloc[:,i].apply(lambda x: re.sub('&#124;', '|', x))\n",
        "    data_clean.iloc[:,i] = data_clean.iloc[:,i].apply(lambda x: re.sub('&#93;', ']', x))\n",
        "    data_clean.iloc[:,i] = data_clean.iloc[:,i].apply(lambda x: re.sub('&#91;', '[', x))\n",
        "    data_clean.iloc[:,i] = data_clean.iloc[:,i].apply(lambda x: re.sub('&gt;', '>', x))\n",
        "    data_clean.iloc[:,i] = data_clean.iloc[:,i].apply(lambda x: re.sub('&lt;', '<', x))\n",
        "\n",
        "  return data_clean"
      ],
      "metadata": {
        "id": "7WMjGu0gm7L9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_path=\"data/en-de/\"\n",
        "en = pd.read_csv(base_path+'idiom_trainplus.en',sep='\\n', header=None,names=['en'])\n",
        "de = pd.read_csv(base_path+'idiom_trainplus.de',sep='\\n', header=None,names=['de'])\n",
        "info = pd.read_csv(base_path+'idiom_trainplus.info',sep='\\t',header=None,names=[\"spread\", \"en_idiom\", \"de_idiom\",'frequency'])\n",
        "train_data = pd.concat([en,de,info],axis=1)\n",
        "train_data.columns = ['input','target',\"spread\", \"en_idiom\", \"de_idiom\",'frequency']\n",
        "train_data = train_data.drop(['spread','frequency',\"en_idiom\", \"de_idiom\"],axis=1)\n",
        "\n",
        "en = pd.read_csv(base_path+'idiom_test.en',sep='\\n', header=None,names=['en'])\n",
        "de = pd.read_csv(base_path+'idiom_test.de',sep='\\n', header=None,names=['de'])\n",
        "test_data = pd.concat([en,de],axis=1)\n",
        "test_data.columns = ['input','target']\n",
        "\n",
        "train_data = clean_dataset(train_data)\n",
        "test_data = clean_dataset(test_data)\n",
        "\n",
        "train_data['input'] = 'translate to german: '+ train_data['input']\n",
        "test_data['input'] = 'translate to german: '+ test_data['input']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data,val_data=train_test_split(train_data, test_size=0.15, random_state=42)"
      ],
      "metadata": {
        "id": "ykw-EnjEZYxV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "AdFqlHrvZ7Oa",
        "outputId": "2a445710-7f03-45e2-d2e7-c02de60ed58b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  input  \\\n",
              "1080  translate to german: EU integration is like a ...   \n",
              "203   translate to german: Whenever we go to a West ...   \n",
              "174   translate to german: I hope that the Irish pre...   \n",
              "772   translate to german: In a nutshell it would in...   \n",
              "120   translate to german: Very well located , easy ...   \n",
              "\n",
              "                                                 target  \n",
              "1080  Die Integration in die EU ist wie Tangotanzen ...  \n",
              "203   Jedes Mal , wenn wir in westafrikanische Lände...  \n",
              "174   Ich möchte , daß die irische Präsidentschaft i...  \n",
              "772   Kurz gesagt würde es die Belastung für den bri...  \n",
              "120   Die Mitarbeiter waren freundlich und das Hotel...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-92a04250-3dcd-4142-b1f3-5810470d5b7d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1080</th>\n",
              "      <td>translate to german: EU integration is like a ...</td>\n",
              "      <td>Die Integration in die EU ist wie Tangotanzen ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>translate to german: Whenever we go to a West ...</td>\n",
              "      <td>Jedes Mal , wenn wir in westafrikanische Lände...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>translate to german: I hope that the Irish pre...</td>\n",
              "      <td>Ich möchte , daß die irische Präsidentschaft i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>772</th>\n",
              "      <td>translate to german: In a nutshell it would in...</td>\n",
              "      <td>Kurz gesagt würde es die Belastung für den bri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>translate to german: Very well located , easy ...</td>\n",
              "      <td>Die Mitarbeiter waren freundlich und das Hotel...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92a04250-3dcd-4142-b1f3-5810470d5b7d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-92a04250-3dcd-4142-b1f3-5810470d5b7d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-92a04250-3dcd-4142-b1f3-5810470d5b7d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "v4j8MNPtN5YU",
        "outputId": "2fb5c8bf-1368-4aaa-fda4-2113349d45ab"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               input  \\\n",
              "0  translate to german: In this day and age , whe...   \n",
              "1  translate to german: In Romania , the election...   \n",
              "2  translate to german: Let us work to close the ...   \n",
              "3  translate to german: The region is easily reac...   \n",
              "4  translate to german: I cannot enter into debat...   \n",
              "\n",
              "                                              target  \n",
              "0  In einer Zeit wie dieser , in der viele offens...  \n",
              "1  In Rumänien wird der Wahlkampf die Chance biet...  \n",
              "2  Gemeinsam sollten wir wirksam die Schlupflöche...  \n",
              "3  Das Gebiet ist mit der Eisenbahn erreichbar , ...  \n",
              "4  Ich kann mich auf keine Diskussion einlassen ,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-07819d0a-fffb-4f9f-83f7-0a8cdbad7323\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>translate to german: In this day and age , whe...</td>\n",
              "      <td>In einer Zeit wie dieser , in der viele offens...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>translate to german: In Romania , the election...</td>\n",
              "      <td>In Rumänien wird der Wahlkampf die Chance biet...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>translate to german: Let us work to close the ...</td>\n",
              "      <td>Gemeinsam sollten wir wirksam die Schlupflöche...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>translate to german: The region is easily reac...</td>\n",
              "      <td>Das Gebiet ist mit der Eisenbahn erreichbar , ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>translate to german: I cannot enter into debat...</td>\n",
              "      <td>Ich kann mich auf keine Diskussion einlassen ,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07819d0a-fffb-4f9f-83f7-0a8cdbad7323')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-07819d0a-fffb-4f9f-83f7-0a8cdbad7323 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-07819d0a-fffb-4f9f-83f7-0a8cdbad7323');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check max length\n",
        "lengths_train_in = train_data[\"input\"].str.split(\" \")\n",
        "lengths_test_in = test_data[\"input\"].str.split(\" \")\n",
        "lengths_val_in = val_data[\"input\"].str.split(\" \")\n",
        "\n",
        "print(\"Max number of tokens input = \", max(lengths_train_in.str.len().max(),lengths_test_in.str.len().max()))\n",
        "\n",
        "lengths_train_tar = train_data[\"target\"].str.split(\" \")\n",
        "lengths_test_tar = test_data[\"target\"].str.split(\" \")\n",
        "lengths_val_tar = val_data[\"target\"].str.split(\" \")\n",
        "\n",
        "print(\"Max number of tokens target = \", max(lengths_train_tar.str.len().max(),lengths_test_tar.str.len().max()))"
      ],
      "metadata": {
        "id": "3InVoeHi9Wyh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd4c6491-2828-489f-ca8d-7d26843ea00c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max number of tokens input =  168\n",
            "Max number of tokens target =  144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Training Model"
      ],
      "metadata": {
        "id": "TMQJTw9DfJIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's define model parameters specific to T5\n",
        "model_params = {\n",
        "    \"MODEL\": \"t5-small\",  # model_type: t5-base/t5-small/t5-large\n",
        "    \"TRAIN_BATCH_SIZE\": 4,  # training batch size\n",
        "    \"VALID_BATCH_SIZE\": 4,  # validation batch size\n",
        "    \"TRAIN_EPOCHS\": 50,  # number of training epochs\n",
        "    \"VAL_EPOCHS\": 1,  # number of validation epochs\n",
        "    \"LEARNING_RATE\": 1e-4,  # learning rate\n",
        "    \"MAX_SOURCE_TEXT_LENGTH\": 107,  # max length of source text\n",
        "    \"MAX_TARGET_TEXT_LENGTH\": 62,  # max length of target text\n",
        "    \"SEED\": 42,  # set seed for reproducibility\n",
        "}\n"
      ],
      "metadata": {
        "id": "UypLE5nTfK5M"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize training and validation loggers to keep track of model loss\n",
        "\n",
        "# training logger to log training loss over the epochs and batches\n",
        "training_logger = Table(\n",
        "    Column(\"Epoch\", justify=\"center\"),\n",
        "    # Column(\"Batch\", justify=\"center\"),\n",
        "    Column(\"Loss\", justify=\"center\"),\n",
        "    title=\"Training Loss\",\n",
        "    pad_edge=False,\n",
        "    box=box.ASCII,\n",
        ")\n",
        "\n",
        "# validation logger to log validation loss over the epochs\n",
        "validation_logger = Table(\n",
        "    Column(\"Epoch\", justify=\"center\"),\n",
        "    Column(\"Loss\", justify=\"center\"),\n",
        "    title=\"Validation Loss\",\n",
        "    pad_edge=False,\n",
        "    box=box.ASCII,\n",
        ")\n"
      ],
      "metadata": {
        "id": "6DgnTr-gMlNA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir outputs"
      ],
      "metadata": {
        "id": "yAV-Zze-YoZh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a0a9be7-a6e8-42e5-baf9-16e386440ead"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘outputs’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "T5Trainer(train_data=train_data, val_data= val_data, source_text=\"input\", target_text=\"target\", model_params=model_params, output_dir=\"outputs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "id": "n6cgmoYBaQV7",
        "outputId": "b0d47d74-035b-4316-bc03-4cd2f92bc097"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m[19:12:14]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mModel\u001b[1m]\u001b[0m: Loading t5-small\u001b[33m...\u001b[0m                     \u001b[2m<ipython-input-8-31ece74cb2e6>\u001b[0m\u001b[2m:\u001b[0m\u001b[2m23\u001b[0m\n",
              "\u001b[2;36m           \u001b[0m                                                 \u001b[2m                                 \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[19:12:14] </span><span style=\"font-weight: bold\">[</span>Model<span style=\"font-weight: bold\">]</span>: Loading t5-small<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-8-31ece74cb2e6&gt;:23</span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                 </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/t5/tokenization_t5.py:169: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m[19:12:29]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mData\u001b[1m]\u001b[0m: Reading data\u001b[33m...\u001b[0m                          \u001b[2m<ipython-input-8-31ece74cb2e6>\u001b[0m\u001b[2m:\u001b[0m\u001b[2m33\u001b[0m\n",
              "\u001b[2;36m           \u001b[0m                                                 \u001b[2m                                 \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[19:12:29] </span><span style=\"font-weight: bold\">[</span>Data<span style=\"font-weight: bold\">]</span>: Reading data<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-8-31ece74cb2e6&gt;:33</span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                 </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                                         Sample Data                                         \u001b[0m\n",
              "+-------------------------------------------------------------------------------------------+\n",
              "|\u001b[1m                source_text                 \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                target_text                 \u001b[0m|\n",
              "|---------------------------------------------+---------------------------------------------|\n",
              "|translate to german: EU integration is like  |      Die Integration in die EU ist wie      |\n",
              "|  a tango . It takes two for it to work .    |  Tangotanzen : Man braucht dazu immer zwei  |\n",
              "|                                             |                  Partner .                  |\n",
              "|  translate to german: Whenever we go to a   |   Jedes Mal , wenn wir in westafrikanische  |\n",
              "|West African country , we can see the extent | Länder kommen , stellen wir fest , wie groß |\n",
              "| to which French influence is still present  |  der französische Einfluss dort noch ist .  |\n",
              "|                  there .                    |                                             |\n",
              "+-------------------------------------------------------------------------------------------+\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                         Sample Data                                         </span>\n",
              "+-------------------------------------------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">                source_text                  </span>|<span style=\"font-weight: bold\">                 target_text                 </span>|\n",
              "|---------------------------------------------+---------------------------------------------|\n",
              "|translate to german: EU integration is like  |      Die Integration in die EU ist wie      |\n",
              "|  a tango . It takes two for it to work .    |  Tangotanzen : Man braucht dazu immer zwei  |\n",
              "|                                             |                  Partner .                  |\n",
              "|  translate to german: Whenever we go to a   |   Jedes Mal , wenn wir in westafrikanische  |\n",
              "|West African country , we can see the extent | Länder kommen , stellen wir fest , wie groß |\n",
              "| to which French influence is still present  |  der französische Einfluss dort noch ist .  |\n",
              "|                  there .                    |                                             |\n",
              "+-------------------------------------------------------------------------------------------+\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "TRAIN Dataset: \u001b[1m(\u001b[0m\u001b[1;36m1956\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TRAIN Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1956</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VALIDATION Dataset: \u001b[1m(\u001b[0m\u001b[1;36m346\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">VALIDATION Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">346</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mInitiating Fine Tuning\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m                      \u001b[2m<ipython-input-8-31ece74cb2e6>\u001b[0m\u001b[2m:\u001b[0m\u001b[2m88\u001b[0m\n",
              "\u001b[2;36m           \u001b[0m                                                 \u001b[2m                                 \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">[</span>Initiating Fine Tuning<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-8-31ece74cb2e6&gt;:88</span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                 </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch:  \u001b[1;36m0\u001b[0m Batch:  \u001b[1;36m0\u001b[0m Loss:  \u001b[1;36m4.016060829162598\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> Batch:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> Loss:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.016060829162598</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch:  \u001b[1;36m0\u001b[0m Batch:  \u001b[1;36m100\u001b[0m Loss:  \u001b[1;36m2.5496857166290283\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> Batch:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> Loss:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.5496857166290283</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch:  \u001b[1;36m0\u001b[0m Batch:  \u001b[1;36m200\u001b[0m Loss:  \u001b[1;36m2.3050968647003174\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> Batch:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200</span> Loss:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.3050968647003174</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch:  \u001b[1;36m0\u001b[0m Batch:  \u001b[1;36m300\u001b[0m Loss:  \u001b[1;36m2.252340078353882\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> Batch:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span> Loss:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.252340078353882</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch:  \u001b[1;36m0\u001b[0m Batch:  \u001b[1;36m400\u001b[0m Loss:  \u001b[1;36m2.373324394226074\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> Batch:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span> Loss:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.373324394226074</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch:  \u001b[1;36m1\u001b[0m Batch:  \u001b[1;36m0\u001b[0m Loss:  \u001b[1;36m1.79466712474823\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> Batch:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> Loss:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.79466712474823</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch:  \u001b[1;36m1\u001b[0m Batch:  \u001b[1;36m100\u001b[0m Loss:  \u001b[1;36m1.056925892829895\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> Batch:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> Loss:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.056925892829895</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch:  \u001b[1;36m1\u001b[0m Batch:  \u001b[1;36m200\u001b[0m Loss:  \u001b[1;36m1.4217126369476318\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> Batch:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200</span> Loss:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.4217126369476318</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch:  \u001b[1;36m1\u001b[0m Batch:  \u001b[1;36m300\u001b[0m Loss:  \u001b[1;36m1.5080888271331787\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> Batch:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span> Loss:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.5080888271331787</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch:  \u001b[1;36m1\u001b[0m Batch:  \u001b[1;36m400\u001b[0m Loss:  \u001b[1;36m1.5163847208023071\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> Batch:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span> Loss:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.5163847208023071</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch:  \u001b[1;36m2\u001b[0m Batch:  \u001b[1;36m0\u001b[0m Loss:  \u001b[1;36m1.2317661046981812\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> Batch:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> Loss:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.2317661046981812</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch:  \u001b[1;36m2\u001b[0m Batch:  \u001b[1;36m100\u001b[0m Loss:  \u001b[1;36m2.1355113983154297\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> Batch:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> Loss:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.1355113983154297</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch:  \u001b[1;36m2\u001b[0m Batch:  \u001b[1;36m200\u001b[0m Loss:  \u001b[1;36m2.1736507415771484\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> Batch:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200</span> Loss:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.1736507415771484</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch:  \u001b[1;36m2\u001b[0m Batch:  \u001b[1;36m300\u001b[0m Loss:  \u001b[1;36m3.1903841495513916\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> Batch:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span> Loss:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.1903841495513916</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch:  \u001b[1;36m2\u001b[0m Batch:  \u001b[1;36m400\u001b[0m Loss:  \u001b[1;36m1.8121647834777832\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> Batch:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span> Loss:  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.8121647834777832</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the training loss to csv\n",
        "table_data = {x.header: [Text.from_markup(y).plain for y in x.cells] for x in training_logger.columns}\n",
        "training_logger_df = pd.DataFrame(table_data)\n",
        "training_logger_df.to_csv(\"outputs/\"+\"train_loss.csv\", sep=\"=\")\n",
        "\n",
        "# Save the validation loss to csv\n",
        "table_data = {x.header: [Text.from_markup(y).plain for y in x.cells] for x in validation_logger.columns}\n",
        "validation_logger_df = pd.DataFrame(table_data)\n",
        "validation_logger_df.to_csv(\"outputs/\"+\"val_loss.csv\", sep=\"=\")"
      ],
      "metadata": {
        "id": "1Yf5Oo1SNecR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the loss\n",
        "train_loss = pd.read_csv(\"outputs/\"+\"train_loss.csv\", sep=\"=\")\n",
        "train_loss.plot(0,2)\n",
        "val_loss = pd.read_csv(\"outputs/\"+\"val_loss.csv\", sep=\"=\")\n",
        "val_loss.plot(0,2)"
      ],
      "metadata": {
        "id": "HEnoiOiXNefH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r outputs.zip outputs"
      ],
      "metadata": {
        "id": "oBRrPNhKwHR8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}